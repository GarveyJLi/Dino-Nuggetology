{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dino-Nuggetology\n",
    "* Team Decaffeinated â€“ So Hirota, Penny King, Garvey Li\n",
    "\n",
    "In this notebook you will be able to use and demo our dino nugget classification model using various photos of dino nuggets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from img_methods import *\n",
    "\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the AutoEncoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 4, stride = 3, padding = 1), # 32, 16, 67, 67\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, 3, stride = 2, padding = 1),# 32, 32, 34, 34\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride = 2, padding = 1), # 32, 32, 17, 17\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 17 * 17, 3000),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3000, 32 * 17 * 17),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(dim = 1, unflattened_size=(32, 17, 17)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride = 2, padding = 1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride = 2, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, 4, stride = 3, padding = 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_border = np.zeros((200, 200))\n",
    "black_border[0:10, :] = 1\n",
    "black_border[190:200, :] = 1\n",
    "black_border[:, 0:10] = 1\n",
    "black_border[:, 190:200] = 1\n",
    "\n",
    "def process_image(img_path):\n",
    "    \"\"\"\n",
    "    Takes in the path of a JPG and creates a new image containing its edges.\n",
    "    \n",
    "    Parameters:\n",
    "    img_path (str): Image path.\n",
    "    \n",
    "    Returns:\n",
    "    img_edge (List): Edge image as a numpy array.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Transforms to do: Mirror, rotate (15 degree increments)\n",
    "    \n",
    "    rotation_degrees = np.arange(0, 360, 15)\n",
    "    \n",
    "    gray_img = load_gray_image(img_path)\n",
    "    gauss_img = gaussian_lpf(gray_img, 42 ** 2)\n",
    "    \n",
    "    gmag, _, _ = edge_detection(gauss_img)\n",
    "    binary_gmag = (gmag > 0.65) - black_border\n",
    "    original_edge = np.clip(binary_gmag * 255, 0, 255)\n",
    "    #mirrored = np.flip(original_edge)\n",
    "    \"\"\"\n",
    "    all_imgs = []\n",
    "    for deg in rotation_degrees:\n",
    "        all_imgs.append(imutils.rotate(original_edge, angle=deg))\n",
    "    for deg in rotation_degrees:\n",
    "        all_imgs.append(imutils.rotate(mirrored, angle=deg))\n",
    "    \"\"\"\n",
    "    #return all_imgs\n",
    "    \n",
    "    return original_edge\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, file_list, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.file_list = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.file_list[0]\n",
    "        img_name = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Define transformations to apply to your images\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((200, 200)), # not necessary, since images are already 200x200\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def anomaly_detection(fp):\n",
    "    fp = [fp]\n",
    "    data = CustomDataset(file_list = fp, root_dir = 'C:\\\\Users\\\\So\\\\Documents\\\\code\\\\datahacks_2024\\\\demo_imgs', transform=transform)\n",
    "\n",
    "    dataloader = DataLoader(data, batch_size=1, shuffle=False)\n",
    "    ae = Conv_AutoEncoder()\n",
    "    ae.load_state_dict(torch.load('C:\\\\Users\\\\So\\\\Documents\\\\code\\\\datahacks_2024\\\\classification\\\\validated_conv_autoencoder_50_epochs.pth'))\n",
    "    \n",
    "    res = {}\n",
    "    for img in dataloader:\n",
    "        # Pass the data through the model\n",
    "        with torch.no_grad():  # No need to track gradients during inference\n",
    "            recon = ae(img)\n",
    "        # recon = ae(img)\n",
    "        res['og'] = img\n",
    "        res['recon'] = recon\n",
    "    \n",
    "    og = 0\n",
    "    recon = 1\n",
    "\n",
    "    original = res['og'][0][0]\n",
    "    recon = res['recon'][0][0]\n",
    "    mse = F.mse_loss(original, recon)\n",
    "\n",
    "    threshold = (0.004964645775481617 + 0.007269915045952306) / 2\n",
    "    res = ''\n",
    "    if threshold > mse:\n",
    "        res = 'NORMAL'\n",
    "    else:\n",
    "        res = 'MALFORMED'\n",
    "    print(f'{res}: reconstruction error: {mse:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial\n",
    "Here is an picture of a triceratops dino nugget at the path `demo_imgs/pte_demo.jpg`\n",
    "\n",
    "<img src='../demo_imgs/pte_demo.jpg' height = 200 width = 200/>\n",
    "\n",
    "Let's use the model to classify the dino species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL: reconstruction error: 0.004169\n"
     ]
    }
   ],
   "source": [
    "img = process_image('C:\\\\Users\\\\So\\\\Documents\\\\code\\\\datahacks_2024\\\\demo_imgs\\\\pte_demo.jpg')\n",
    "Image.fromarray(img).convert('RGB').save('C:\\\\Users\\\\So\\\\Documents\\\\code\\\\datahacks_2024\\\\demo_imgs\\\\temp.jpeg')\n",
    "\n",
    "anomaly_detection('temp.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example using a deformed dino nugget.\n",
    "\n",
    "Below is the picture we will use. The path is: `demo_imgs/deformed_nugget.jpg`\n",
    "\n",
    "<img src='../demo_imgs/deformed_nugget.jpg' height = 200 width = 200/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MALFORMED: reconstruction error: 0.006177\n"
     ]
    }
   ],
   "source": [
    "img = process_image('C:\\\\Users\\\\So\\\\Documents\\\\code\\\\datahacks_2024\\\\demo_imgs\\\\deformed_nugget.jpg')\n",
    "Image.fromarray(img).convert('RGB').save('C:\\\\Users\\\\So\\\\Documents\\\\code\\\\datahacks_2024\\\\demo_imgs\\\\temp.jpeg')\n",
    "\n",
    "anomaly_detection('temp.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn!\n",
    "Feel free to try on your own now. You can find various different images to use for the model in the folder `demo_imgs\\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shazam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
